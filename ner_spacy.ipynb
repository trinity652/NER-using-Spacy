{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataset\n",
    "items = ['milk', 'cheese', 'butter', 'yogurt', 'cream', 'bread', 'croissant', 'bagel', 'brioche', 'aspirin', \n",
    "         'ibuprofen', 'paracetamol', 'antibiotic', 'vitamin', 'cough', 'syrup', 'tablet', 'ointment', 'rice', \n",
    "         'pasta', 'cereal', 'flour', 'sugar', 'oil', 'grain', 'seasoning', 'spice', 'chicken', 'beef', 'pork', \n",
    "         'fish', 'salmon', 'tuna', 'shrimp', 'bacon', 'sausage', 'apple', 'banana', 'carrot', 'lettuce', 'tomato', \n",
    "         'berry', 'orange', 'peach', 'grape', 'water', 'juice', 'soda', 'coffee', 'tea', 'beer', 'wine', 'liquor', \n",
    "         'drink', 'shampoo', 'soap', 'lotion', 'perfume', 'makeup', 'deodorant', 'lipstick', 'nail']\n",
    "\n",
    "quantity_descriptors = [\n",
    "    \"1-liter of\", \"500g of\", \"Pack of 12\", \"Single\", \"Pack of 6\", \"Dozen\",\n",
    "    \"30\", \"100 tablets\", \"10 sachets\",\n",
    "    \"1kg of\", \"500g packet of\", \"2lb bag of\", \"500g of\", \"1kg packet of\", \"Bag of 5\", \"1-liter bottle of\",\n",
    "    \"6-pack of\", \"Case of 24\", \"100ml of\", \"250ml bottle of\", \"Tube of\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1-liter of milk', {'entities': [(0, 7, 'QUANTITY')]}), ('500g of cheese', {'entities': [(0, 4, 'QUANTITY')]}), ('Pack of 12 butter', {'entities': [(0, 4, 'QUANTITY')]}), ('Single yogurt', {'entities': [(0, 6, 'QUANTITY')]}), ('Pack of 6 cream', {'entities': [(0, 4, 'QUANTITY')]}), ('Dozen bread', {'entities': [(0, 5, 'QUANTITY')]}), ('30 croissant', {'entities': [(0, 2, 'QUANTITY')]}), ('100 tablets bagel', {'entities': [(0, 3, 'QUANTITY')]}), ('10 sachets brioche', {'entities': [(0, 2, 'QUANTITY')]}), ('1kg of aspirin', {'entities': [(0, 3, 'QUANTITY')]}), ('500g packet of ibuprofen', {'entities': [(0, 4, 'QUANTITY')]}), ('2lb bag of paracetamol', {'entities': [(0, 3, 'QUANTITY')]}), ('500g of antibiotic', {'entities': [(0, 4, 'QUANTITY')]}), ('1kg packet of vitamin', {'entities': [(0, 3, 'QUANTITY')]}), ('Bag of 5 cough', {'entities': [(0, 3, 'QUANTITY')]}), ('1-liter bottle of syrup', {'entities': [(0, 7, 'QUANTITY')]}), ('6-pack of tablet', {'entities': [(0, 6, 'QUANTITY')]}), ('Case of 24 ointment', {'entities': [(0, 4, 'QUANTITY')]}), ('100ml of rice', {'entities': [(0, 5, 'QUANTITY')]}), ('250ml bottle of pasta', {'entities': [(0, 5, 'QUANTITY')]}), ('Tube of cereal', {'entities': [(0, 4, 'QUANTITY')]})]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = [\n",
    "    (f\"{q} {item}\", {\"entities\": [(0, len(q) if q.find(' ') == -1 else q.find(' '), \"QUANTITY\")]})\n",
    "    for q, item in zip(quantity_descriptors, items)\n",
    "]\n",
    "\n",
    "print(TRAIN_DATA)\n",
    "print(len(TRAIN_DATA))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1-liter of milk', {'entities': [(0, 7, 'QUANTITY')]}), ('500g of cheese', {'entities': [(0, 4, 'QUANTITY')]}), ('Pack of 12 butter', {'entities': [(0, 4, 'QUANTITY')]}), ('Single yogurt', {'entities': [(0, 6, 'QUANTITY')]}), ('Pack of 6 cream', {'entities': [(0, 4, 'QUANTITY')]}), ('Dozen bread', {'entities': [(0, 5, 'QUANTITY')]}), ('30 croissant', {'entities': [(0, 2, 'QUANTITY')]}), ('100 tablets bagel', {'entities': [(0, 3, 'QUANTITY')]}), ('10 sachets brioche', {'entities': [(0, 2, 'QUANTITY')]}), ('1kg of aspirin', {'entities': [(0, 3, 'QUANTITY')]}), ('500g packet of ibuprofen', {'entities': [(0, 4, 'QUANTITY')]}), ('2lb bag of paracetamol', {'entities': [(0, 3, 'QUANTITY')]}), ('500g of antibiotic', {'entities': [(0, 4, 'QUANTITY')]}), ('1kg packet of vitamin', {'entities': [(0, 3, 'QUANTITY')]}), ('Bag of 5 cough', {'entities': [(0, 3, 'QUANTITY')]}), ('1-liter bottle of syrup', {'entities': [(0, 7, 'QUANTITY')]}), ('6-pack of tablet', {'entities': [(0, 6, 'QUANTITY')]}), ('Case of 24 ointment', {'entities': [(0, 4, 'QUANTITY')]}), ('100ml of rice', {'entities': [(0, 5, 'QUANTITY')]}), ('250ml bottle of pasta', {'entities': [(0, 5, 'QUANTITY')]}), ('Tube of cereal', {'entities': [(0, 4, 'QUANTITY')]}), ('Pack of 10 - Premium Cotton Towels', {'entities': [(8, 10, 'QUANTITY')]}), ('Set of Three Handcrafted Pottery Vases', {'entities': [(7, 12, 'QUANTITY')]}), ('5-Gallon High-Efficiency Concentrated Laundry Detergent', {'entities': [(0, 8, 'QUANTITY')]}), ('Bundle of 50 LED Light Bulbs - Energy Saving', {'entities': [(10, 12, 'QUANTITY')]}), ('Double Pack: Two 24oz Stainless Steel Water Bottles', {'entities': [(13, 16, 'QUANTITY'), (17, 21, 'QUANTITY')]}), ('Apple iPhone 11 64GB Red Unlocked - 3 Network', {'entities': [(13, 15, 'QUANTITY'), (16, 20, 'QUANTITY'), (36, 37, 'QUANTITY')]}), ('Amazon Kindle 2019 Edition', {'entities': [(14, 18, 'QUANTITY')]})]\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "products = [\n",
    "    {\"id\": 1, \"title\": \"Pack of 10 - Premium Cotton Towels\"},\n",
    "    {\"id\": 2, \"title\": \"Set of Three Handcrafted Pottery Vases\"},\n",
    "    {\"id\": 3, \"title\": \"5-Gallon High-Efficiency Concentrated Laundry Detergent\"},\n",
    "    {\"id\": 4, \"title\": \"Bundle of 50 LED Light Bulbs - Energy Saving\"},\n",
    "    {\"id\": 5, \"title\": \"Double Pack: Two 24oz Stainless Steel Water Bottles\"},\n",
    "    {\"id\": 6, \"title\": \"Apple iPhone 11 64GB Red Unlocked - 3 Network\"},\n",
    "    {\"id\": 7, \"title\": \"Amazon Kindle 2019 Edition\"}\n",
    "]\n",
    "\n",
    "# Function to find numbers and associated phrases indicating quantities\n",
    "def extract_quantity(text):\n",
    "    import re\n",
    "    # This regex pattern is quite simplistic and may need to be refined for more complex scenarios\n",
    "    pattern = r'(\\b\\d+-?[a-zA-Z]*|\\b[Tt]wo|\\b[Tt]hree|\\b[Ff]our|\\b[Ff]ive|\\b[Ss]ix|\\b[Ss]even|\\b[Ee]ight|\\b[Nn]ine|\\b[Tt]en)\\b'\n",
    "    matches = re.finditer(pattern, text)\n",
    "    return [(match.start(), match.end(), 'QUANTITY') for match in matches]\n",
    "\n",
    "# Generate training data\n",
    "for product in products:\n",
    "    title = product['title']\n",
    "    entities = extract_quantity(title)\n",
    "    if entities:\n",
    "        TRAIN_DATA.append((title, {\"entities\": entities}))\n",
    "\n",
    "print(TRAIN_DATA)\n",
    "print(len(TRAIN_DATA))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load a pre-trained model or create a new one\n",
    "nlp = spacy.blank(\"en\")  # For a new model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")  # To update an existing model\n",
    "\n",
    "# Add the NER pipeline if it's not already there\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe('ner')  # Add the NER pipe this way\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Add the new entity type to the pipeline\n",
    "ner.add_label(\"QUANTITY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 70.54023786378093}\n",
      "{'ner': 51.443430895451456}\n",
      "{'ner': 48.272044919780456}\n",
      "{'ner': 45.21844068257633}\n",
      "{'ner': 33.7901992043992}\n",
      "{'ner': 28.776486041644663}\n",
      "{'ner': 30.37015892824453}\n",
      "{'ner': 23.058868124638277}\n",
      "{'ner': 29.056196646997787}\n",
      "{'ner': 23.55485140323574}\n"
     ]
    }
   ],
   "source": [
    "from spacy.training import Example\n",
    "import random\n",
    "\n",
    "# Prepare the training data\n",
    "examples = [Example.from_dict(nlp.make_doc(text), annotations) for text, annotations in TRAIN_DATA]\n",
    "\n",
    "# Train the model\n",
    "optimizer = nlp.begin_training()\n",
    "for itn in range(10):  # Number of training iterations\n",
    "    random.shuffle(examples)\n",
    "    losses = {}\n",
    "    for example in examples:\n",
    "        nlp.update([example], drop=0.5, losses=losses)\n",
    "    print(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box QUANTITY\n",
      "3 QUANTITY\n",
      "T QUANTITY\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Box of 3 Men's T Shirts\"\n",
    "doc = nlp(test_text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "product_repo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
